{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3_prompt",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Q3\n",
    "\n",
    "CodeNeuro is a project run out of HHMI Janelia Farms which looks at designing algorithms to automatically identify neurons in time-lapse microscope data. The competition is called \"NeuroFinder\": \n",
    "http://neurofinder.codeneuro.org/\n",
    "\n",
    "The goal of the project is to use data that look like this\n",
    "\n",
    "![unlabeled](movie-0.png)\n",
    "\n",
    "and automatically segment out all the neurons in the image, like so\n",
    "\n",
    "![labeled](zooming-0.png)\n",
    "\n",
    "As you can probably imagine, storing this information is tricky, requiring a great deal of specifics. On the website, JSON format is used to submit predictions. The format is as follows:\n",
    "\n",
    " - The first layer is a **list**, where each item in the list is a dictionary. Each item (dictionary) corresponds to a single dataset.\n",
    " - One of the dictionaries will contain two keys: `dataset`, which gives the name of the dataset as the value (a string), and `regions`, which contains a **list** of all the regions found in that dataset.\n",
    " - A single item in the list of regions is a **dictionary**, with one key: `coordinates`.\n",
    " - The value for `coordinates` is, again, a **list**, where each element of the list is an `(x, y)` pair that specifies a pixel in the region.\n",
    " \n",
    "That's a lot, for sure. Here's an example of a JSON structure representing two different datasets, where one dataset has only 1 region and the other dataset has 2 regions:\n",
    "\n",
    "```\n",
    "'[\n",
    "  {\"dataset\": \"d1\", \"regions\":\n",
    "    [\n",
    "      {\"coordinates\": [[1, 2], [3, 4], [4, 5]]}\n",
    "    ]\n",
    "  },\n",
    "  \n",
    "  {\"dataset\": \"d2\", \"regions\":\n",
    "    [\n",
    "      {\"coordinates\": [[2, 3], [4, 10]]},\n",
    "      {\"coordinates\": [[20, 20], [20, 21], [22, 23]]}\n",
    "    ]\n",
    "  }\n",
    "]'\n",
    "```\n",
    "\n",
    "You have two datasets, `d1` and `d2`, represented as two elements in the outermost list. Those two dictionaries have two keys, `dataset` (the name of the dataset) and `regions` (the list of regions outlining neurons present in that dataset). The `regions` field is a list of dictionaries, and the length of the list is how many distinct regions/neurons there are in that dataset. For example, in `d1` above, there is only 1 neuron/region, but in `d2`, there are 2 neurons/regions. Each region is just a list of `(x, y)` tuple integers that specify a pixel in the image dataset that is part of the region.\n",
    "\n",
    "*WHEW*. That's a lot. We'll try to start things off slowly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a_prompt",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### A\n",
    "\n",
    "Write a function, `count_datasets`, which returns the number of datasets in the provided JSON file.\n",
    "\n",
    "The function will accept one argument: `json_file`, which is the name of a JSON file on the hard disk that represents a submission file for CodeNeuro.\n",
    "\n",
    "Your function should return an integer: the number of datasets present in the JSON input file.\n",
    "\n",
    "This function should read the file off the hard disk, count the number of datasets in the file, and return that number. It should also be able to handle file exceptions gracefully; if an error is encountered, return `-1` to represent this. Otherwise, the return value should always be 0 or greater.\n",
    "\n",
    "You can use the `json` Python library; otherwise, no other imports are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3a_test1",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    count_datasets\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3a_test2",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "c = count_datasets(\"submission_partial.json\")\n",
    "assert c == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3a_test3",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "c = count_datasets(\"submission_full.json\")\n",
    "assert c == 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3a_test4",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = count_datasets(\"submission_nonexistent.json\")\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b_prompt",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### B\n",
    "\n",
    "Write a function, `get_dataset_by_index`, which returns a certain dataset from the file.\n",
    "\n",
    "This function should take two arguments: the name of the JSON file on the filesystem, and the *integer index* of the dataset to return from that JSON file.\n",
    "\n",
    "This function should return the dictionary corresponding to the dataset in the JSON file, or `None` if an invalid index is supplied (e.g. specified 10 when there are only 4 datasets, or a negative number, or a float/string/list/non-integer type). It should also be able to handle file-related errors.\n",
    "\n",
    "You can use the `json` Python library; otherwise, no other imports are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3b_test1",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    get_dataset_by_index\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3b_test2",
     "locked": true,
     "points": 6,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "d = json.loads(open(\"partial_1.json\", \"r\").read())\n",
    "assert d == get_dataset_by_index(\"submission_partial.json\", 1)\n",
    "\n",
    "d = json.loads(open(\"full_8.json\", \"r\").read())\n",
    "assert d == get_dataset_by_index(\"submission_full.json\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3b_test3",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = get_dataset_by_index(\"submission_partial.json\", 5)\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3b_test4",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = get_dataset_by_index(\"submission_nonexistent.json\", 4983)\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3c_prompt",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### C\n",
    "\n",
    "Write a function, `get_dataset_by_name`, which is functionally identical to `get_dataset_by_index` except rather than retrieving a dataset by the integer index, you instead return a dataset by its *string name*.\n",
    "\n",
    "This function should take two arguments: the name of the JSON file on the filesystem, and the *string name* of the dataset to return from that JSON file.\n",
    "\n",
    "This function should return the dictionary corresponding to the dataset in the JSON file, or `None` if an invalid name is supplied. It should also be able to handle file-related errors.\n",
    "\n",
    "You can use the `json` Python library; otherwise, no other imports are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3c",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3c_test1",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    get_dataset_by_name\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3c_test2",
     "locked": true,
     "points": 6,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "d = json.loads(open(\"partial_1.json\", \"r\").read())\n",
    "assert d == get_dataset_by_name(\"submission_partial.json\", \"01.01.test\")\n",
    "\n",
    "d = json.loads(open(\"full_8.json\", \"r\").read())\n",
    "assert d == get_dataset_by_name(\"submission_full.json\", \"04.01.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3c_test3",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = get_dataset_by_name(\"submission_partial.json\", \"nonexistent\")\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3c_test4",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = get_dataset_by_name(\"submission_nonexistent.json\", \"02.00.test\")\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3d_prompt",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### D\n",
    "\n",
    "Write a function, `count_pixels_in_dataset`, which returns the number of pixels found in *all regions* of a particular dataset.\n",
    "\n",
    "This function should take two arguments:\n",
    " - the string name of the JSON file containing all the datasets on the filesystem\n",
    " - the string name of the dataset to search\n",
    " \n",
    "This function should return one integer: the number of pixels identified in regions in that dataset. This should be returned from the function. Each individual pixel is a single pair of `(x, y)` numbers (that counts as 1).\n",
    "\n",
    "If any file-related errors are encountered, or an incorrect dataset name specified, the function should return `-1`.\n",
    "\n",
    "You can use the `json` Python library, **or other functions you've already written in this question**; otherwise, no other imports are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "q3d",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3d_test1",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    count_pixels_in_dataset\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3d_test2",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert 29476 == count_pixels_in_dataset(\"submission_full.json\", \"01.01.test\")\n",
    "assert 30231 == count_pixels_in_dataset(\"submission_full.json\", \"04.01.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "q3d_test3",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    c = count_pixels_in_dataset(\"submission_partial.json\", \"02.00.test\")\n",
    "except:\n",
    "    assert False\n",
    "else:\n",
    "    assert c == -1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
